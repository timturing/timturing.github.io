关于隐马尔可夫是什么参考[here](https://blog.csdn.net/u012421852/article/details/80186703)，原文应该也是参考李航的《统计学习方法》

## 隐马尔可夫模型与马尔科夫链的区别

普通的马尔科夫链是**状态可见**的，而隐马尔可夫模型是**状态不可见**的，只能通过观测到的结果来推测状态。也就是说马克可夫链可以理解为只有两层，时间层和状态层，而隐马尔可夫模型可以理解为三层，时间层，状态层和观测层。这也就是为什么马尔科夫链只用两个参数就可以描述，而隐马尔可夫模型需要三个参数来描述。

马尔科夫链的**状态转移矩阵**大小是**状态数** x **状态数**，而隐马尔可夫模型除此之外还包含另外一个与观测序列相关的矩阵，大小是**状态数** x **观测数**，这在某种意义上与RNN的思想是一样的，就是在每个时间步都有一个输出，而这个输出正形成了观测序列。

同时我们能意识到，隐马尔可夫确确实实就是个**模型**，它是由参数确定的一个**类似随机变量、随机过程的存在**，它并不是一个**样本**，而是一个类似**分布**的存在。相反，观测序列才是真正意义上的**样本**，它是在特定的参数（状态数，转移的概率值等）下**生成**的。

也正是因此，我们才会有类似样本推断总体的问题，比如已知观测序列，用于推断模型的参数，使得在该参数设置下出现这些样本的概率最大，也就是最大似然估计。

## 隐马尔可夫和EM算法的关系

隐马尔可夫里面，如果每个时间步都是同分布的，那么我们就可以引出EM的推导过程：因为此时从状态数到观测数的那个矩阵是唯一的（因为分布唯一，也就是说某个盒子里拿出某个球的概率应该是唯一的，只是每次拿某个盒子的概率不一样）；既然如此，我们自然就可以先假设这个矩阵的值是随机值，然后通过多次观测的结果（样本）来修订这个值直到这个分布是一个合理的值为止）。此时就相当于有两个事件：正向是，在这个盒子里拿的话，球的可能性时多少；反向是出现这个球的情况下，是这个盒子的概率是多少